{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1a44494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d039e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model =  ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2299745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7222498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Can you explain me Gen-AI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2442bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.stream(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9dbc72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## What is Generative AI (Gen‑AI)?\n",
      "\n",
      "**Generative AI** refers to a class of artificial‑intelligence models that can *create* new content—text, images, audio, video, code, and even 3D models—based on patterns they learned from large amounts of data. Unlike “discriminative” models that classify or predict labels (e.g., spam vs. ham), generative models *produce* data that resembles what they were trained on.\n",
      "\n",
      "---\n",
      "\n",
      "### Core Ideas\n",
      "\n",
      "| Concept | What it Means | Example |\n",
      "|---------|---------------|---------|\n",
      "| **Training on massive datasets** | Models see billions of examples, learning statistical regularities. | GPT‑4 trained on a wide mix of books, websites, code, etc. |\n",
      "| **Probabilistic generation** | They output the next token (word, pixel, note) based on learned probability distributions. | Predicting the next word in a sentence. |\n",
      "| **Latent space representation** | Data is compressed into a lower‑dimensional “latent” space where similar items cluster together. | A latent vector that captures the essence of a painting style. |\n",
      "| **Fine‑tuning & prompting** | The base model can be nudged to produce specific styles or answers. | Prompting GPT‑4 to write a poem in Shakespearean style. |\n",
      "\n",
      "---\n",
      "\n",
      "### How It Works (High‑Level)\n",
      "\n",
      "1. **Data Collection**  \n",
      "   - Gather a huge corpus (text, images, etc.) from the internet, licensed sources, or proprietary datasets.\n",
      "\n",
      "2. **Pre‑training**  \n",
      "   - Use unsupervised or self‑supervised objectives (e.g., next‑token prediction, masked language modeling).  \n",
      "   - The model learns to encode patterns without explicit labels.\n",
      "\n",
      "3. **Architecture**  \n",
      "   - **Transformers** dominate: self‑attention layers allow the model to weigh all parts of the input simultaneously.  \n",
      "   - Other architectures: diffusion models (for images), VQ‑VAE, GANs, autoregressive models, etc.\n",
      "\n",
      "4. **Fine‑tuning (Optional)**  \n",
      "   - Supervised training on a narrower domain or with human‑feedback (RLHF) to improve safety, style, or factual accuracy.\n",
      "\n",
      "5. **Inference / Generation**  \n",
      "   - Provide a *prompt* (seed text, image, etc.).  \n",
      "   - The model samples from its learned distribution, generating new content token by token.\n",
      "\n",
      "---\n",
      "\n",
      "### Popular Generative Models\n",
      "\n",
      "| Domain | Model | Key Features |\n",
      "|--------|-------|--------------|\n",
      "| **Text** | GPT‑4, Claude, Llama 2 | Large transformer, few‑shot prompting, fine‑tuned for safety. |\n",
      "| **Images** | DALL‑E 2, Stable Diffusion, Midjourney | Diffusion models that iteratively denoise latent images. |\n",
      "| **Audio** | Jukebox, MusicLM | Autoregressive models generating raw audio or symbolic music. |\n",
      "| **Video** | Make-A-Video, Phenaki | Temporal diffusion or autoregressive generation. |\n",
      "| **Code** | Codex, GitHub Copilot | Trained on public code repositories, can write or complete code. |\n",
      "\n",
      "---\n",
      "\n",
      "### Use Cases\n",
      "\n",
      "| Category | Examples |\n",
      "|----------|----------|\n",
      "| **Content Creation** | AI‑generated articles, marketing copy, social media posts. |\n",
      "| **Design & Art** | Generating concept art, interior designs, fashion sketches. |\n",
      "| **Entertainment** | Writing scripts, creating music, generating game assets. |\n",
      "| **Productivity** | Drafting emails, summarizing documents, translating text. |\n",
      "| **Education** | Generating practice problems, tutoring explanations, language learning. |\n",
      "| **Healthcare** | Synthesizing medical images for training, generating patient notes. |\n",
      "| **Research** | Simulating data, generating hypotheses, automating literature reviews. |\n",
      "\n",
      "---\n",
      "\n",
      "### Key Advantages\n",
      "\n",
      "- **Speed & Scale**: Produce large volumes of content in seconds.  \n",
      "- **Creativity Boost**: Provide novel ideas or variations that humans might not think of.  \n",
      "- **Personalization**: Tailor outputs to user preferences or constraints.  \n",
      "- **Accessibility**: Democratize content creation for non‑experts (e.g., small businesses, students).  \n",
      "\n",
      "---\n",
      "\n",
      "### Important Challenges & Risks\n",
      "\n",
      "| Issue | Why It Matters | Mitigations |\n",
      "|-------|----------------|-------------|\n",
      "| **Hallucinations** | Models may fabricate facts or plausible but false statements. | Fact‑checking, prompting for citations, hybrid human‑AI workflows. |\n",
      "| **Bias & Fairness** | Training data can encode societal biases. | Diverse datasets, bias audits, fine‑tuning for fairness. |\n",
      "| **Copyright & Plagiarism** | Generated text may inadvertently echo copyrighted material. | Use of watermarking, copyright‑aware training, user guidelines. |\n",
      "| **Misinformation** | Easy to produce realistic fake news or deepfakes. | Detection tools, transparency about AI‑generated content. |\n",
      "| **Energy & Compute** | Training huge models consumes significant resources. | Efficient architectures, federated learning, carbon‑offset initiatives. |\n",
      "\n",
      "---\n",
      "\n",
      "### Future Directions\n",
      "\n",
      "- **Multimodal Integration**: Seamlessly combining text, vision, audio, and sensor data.  \n",
      "- **Few‑Shot & Zero‑Shot Learning**: Models that adapt to new tasks with minimal examples.  \n",
      "- **Explainability**: Understanding why a model generated a specific output.  \n",
      "- **Robustness & Safety**: Building guardrails against harmful or unintended outputs.  \n",
      "- **Edge Deployment**: Running lightweight generative models on mobile or IoT devices.  \n",
      "\n",
      "---\n",
      "\n",
      "### Quick Takeaway\n",
      "\n",
      "Generative AI is a powerful family of models that learn patterns from vast data and can produce new, high‑quality content across many domains. It’s transforming how we create, design, and communicate, while also bringing new ethical, legal, and technical challenges that researchers, developers, and users must navigate carefully."
     ]
    }
   ],
   "source": [
    "for chunk in response:\n",
    "     print(chunk.content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
