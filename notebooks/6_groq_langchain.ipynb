{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989e20b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f564cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774a55c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4442c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### What is Generative AI (Gen‑AI)?\n",
      "\n",
      "**Generative AI** refers to a class of artificial‑intelligence systems that can *create* new content—text, images, audio, video, code, and even 3‑D models—rather than just analyze or classify existing data.  \n",
      "The core idea is to learn a statistical model of a data distribution and then sample from that model to produce something that resembles the original data but is not a copy of any single training example.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Core Concepts\n",
      "\n",
      "| Concept | What it means | Why it matters for Gen‑AI |\n",
      "|---------|---------------|---------------------------|\n",
      "| **Probabilistic modeling** | The AI learns the probability distribution \\(P(x)\\) of the data \\(x\\). | Enables the system to generate plausible samples. |\n",
      "| **Latent space** | A compressed, often lower‑dimensional representation of data. | Allows smooth interpolation, manipulation, and generation. |\n",
      "| **Autoregressive models** | Predict the next token (word, pixel, etc.) conditioned on previous ones. | Power behind many text generators (GPT) and image models (PixelCNN). |\n",
      "| **Diffusion models** | Add noise to data progressively and learn to reverse the process. | State‑of‑the‑art for high‑fidelity image & audio synthesis. |\n",
      "| **Generative Adversarial Networks (GANs)** | Two networks (generator & discriminator) compete; the generator learns to fool the discriminator. | Historically important for realistic image generation. |\n",
      "| **Variational Autoencoders (VAEs)** | Encode data into a latent space with a probabilistic decoder. | Useful for structured generation & latent‑space editing. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Historical Milestones\n",
      "\n",
      "| Year | Milestone | Impact |\n",
      "|------|-----------|--------|\n",
      "| 1993 | **Bengio et al.** introduced **Restricted Boltzmann Machines** (RBMs). | Early neural generative models. |\n",
      "| 2014 | **GANs** (Goodfellow et al.) | Sparked a wave of research into realistic image synthesis. |\n",
      "| 2015 | **VAE** (Kingma & Welling) | Formalized probabilistic autoencoders. |\n",
      "| 2018 | **Transformer** (Attention‑is‑All‑You‑Need) | Revolutionized sequence modeling. |\n",
      "| 2019 | **GPT‑2** (OpenAI) | Demonstrated large‑scale text generation. |\n",
      "| 2020 | **DALL‑E** | Showed text‑to‑image generation with transformers. |\n",
      "| 2021 | **CLIP** (OpenAI) | Joint vision‑language embeddings for zero‑shot tasks. |\n",
      "| 2022 | **Stable Diffusion** & **Midjourney** | Diffusion models democratized high‑quality image generation. |\n",
      "| 2023 | **GPT‑4** & **Claude 3** | Multimodal, large‑context, and more aligned models. |\n",
      "| 2024 | **Sora** (text‑to‑video) & **AudioGen** (text‑to‑audio) | Generative AI expanding into video & audio. |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. How Do Generative Models Work? (Simplified)\n",
      "\n",
      "1. **Data Collection**  \n",
      "   Gather a large, diverse dataset (e.g., books, web pages, images).\n",
      "\n",
      "2. **Model Architecture**  \n",
      "   Choose a suitable architecture: Transformer, VAE, Diffusion, GAN, etc.\n",
      "\n",
      "3. **Training**  \n",
      "   * **Objective**: Maximize likelihood or minimize reconstruction error; for GANs, minimize a game‑theoretic loss.  \n",
      "   * **Optimization**: Gradient descent + backpropagation.\n",
      "\n",
      "4. **Sampling**  \n",
      "   * **Autoregressive**: Generate token by token, sampling from the predicted distribution.  \n",
      "   * **Diffusion**: Start from noise, iteratively denoise.  \n",
      "   * **GAN**: Sample latent vector → generator → image.\n",
      "\n",
      "5. **Post‑processing**  \n",
      "   Apply filtering, upsampling, or user‑controlled prompts to refine output.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Popular Generative Models\n",
      "\n",
      "| Model | Domain | Key Features | Typical Use Cases |\n",
      "|-------|--------|--------------|-------------------|\n",
      "| **GPT‑4 / GPT‑3.5** | Text | 175B+ parameters, few‑shot learning, multimodal (image‑to‑text) | Chatbots, content creation, code generation |\n",
      "| **Claude 3** | Text | Strong alignment, safer outputs | Enterprise chat, knowledge bases |\n",
      "| **Stable Diffusion** | Images | Open‑source, latent diffusion, high‑resolution | Art generation, design, in‑painting |\n",
      "| **Midjourney** | Images | Community‑driven, stylized outputs | Concept art, marketing visuals |\n",
      "| **DALL‑E 3** | Images | Text‑to‑image, fine‑grained control | Product mock‑ups, illustrations |\n",
      "| **AudioGen / Jukebox** | Audio | Text‑to‑music, waveform synthesis | Music production, background scores |\n",
      "| **Sora** | Video | Text‑to‑video, up to 4‑K resolution | Film pre‑visualization, marketing clips |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Applications Across Industries\n",
      "\n",
      "| Industry | Example Use Cases | Value Added |\n",
      "|----------|------------------|-------------|\n",
      "| **Creative Arts** | AI‑generated paintings, music, scripts | Rapid prototyping, new styles |\n",
      "| **Advertising** | Personalized ad creatives, dynamic copy | Higher engagement, faster turnaround |\n",
      "| **Gaming** | Procedural worlds, NPC dialogue | Richer content, lower dev cost |\n",
      "| **Healthcare** | Synthetic patient data for research | Preserve privacy, augment datasets |\n",
      "| **Finance** | Automated report generation, risk modeling | Faster insights, reduce human error |\n",
      "| **Education** | Adaptive tutoring, content generation | Personalized learning paths |\n",
      "| **Legal** | Drafting contracts, summarizing documents | Speed, consistency |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Challenges & Ethical Considerations\n",
      "\n",
      "| Issue | Why It Matters | Mitigations |\n",
      "|-------|----------------|-------------|\n",
      "| **Hallucinations** | Generated content may be plausible but false. | Prompt engineering, post‑verification, user warnings |\n",
      "| **Bias & Fairness** | Models reflect biases in training data. | Diverse datasets, bias‑audit frameworks |\n",
      "| **Copyright & Ownership** | Generated content may infringe or be derivative. | Copyright‑aware training, licensing checks |\n",
      "| **Deepfakes** | Realistic synthetic media can spread misinformation. | Watermarking, detection tools, policy |\n",
      "| **Environmental Impact** | Training large models consumes energy. | Efficient architectures, green‑energy data centers |\n",
      "| **Misuse** | Spam, phishing, disinformation. | Guardrails, usage monitoring, policy enforcement |\n",
      "\n",
      "---\n",
      "\n",
      "## 7. The Future Landscape\n",
      "\n",
      "1. **Multimodal Integration**  \n",
      "   Combining text, image, audio, and video in a single model (e.g., GPT‑4V, Sora).\n",
      "\n",
      "2. **Interactive & Adaptive Models**  \n",
      "   Models that learn from user feedback in real time, refining outputs.\n",
      "\n",
      "3. **Personalization**  \n",
      "   Fine‑tuning on individual user data (with privacy safeguards) to create unique AI “assistants”.\n",
      "\n",
      "4. **Explainability & Transparency**  \n",
      "   Tools that help users understand why a model produced a specific output.\n",
      "\n",
      "5. **Regulatory Frameworks**  \n",
      "   International guidelines on AI-generated content, especially for media and public communication.\n",
      "\n",
      "6. **Edge & On‑Device Generation**  \n",
      "   Lightweight models enabling real‑time generation on smartphones and IoT devices.\n",
      "\n",
      "---\n",
      "\n",
      "## 8. Quick Glossary\n",
      "\n",
      "| Term | Definition |\n",
      "|------|------------|\n",
      "| **Token** | Smallest unit processed by a language model (word, sub‑word, or character). |\n",
      "| **Context Window** | Number of tokens a model can consider at once (e.g., 8,192 tokens in GPT‑4). |\n",
      "| **Prompt** | Input text (or other modalities) that guides generation. |\n",
      "| **Latent Variable** | Hidden representation learned by the model. |\n",
      "| **Diffusion Process** | Gradual corruption of data followed by learned denoising. |\n",
      "| **Zero‑shot** | Ability to perform a task without explicit training on that task. |\n",
      "| **Few‑shot** | Ability to adapt with only a handful of examples. |\n",
      "\n",
      "---\n",
      "\n",
      "### Bottom Line\n",
      "\n",
      "Generative AI is transforming how we create and consume content. By learning the underlying patterns in massive datasets, these models can produce new, high‑quality artifacts across text, images, audio, and beyond. While the technology offers tremendous opportunities—from accelerating design workflows to democratizing creative expression—it also brings significant ethical, legal, and societal challenges that researchers, developers, and policymakers must address collaboratively.\n"
     ]
    }
   ],
   "source": [
    "res = llm.invoke(\"Can you explain me Gen_AI?\")\n",
    "print(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
